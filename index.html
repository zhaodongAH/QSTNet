
<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
    <meta name="description" content="DESCRIPTION META TAG">
    <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
    <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
    <meta property="og:url" content="URL OF THE WEBSITE"/>
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
    <meta property="og:image" content="static/image/your_banner_image.png"/>
    <meta property="og:image:width" content="1200"/>
    <meta property="og:image:height" content="630"/>


    <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
    <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
    <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
    <meta name="twitter:card" content="summary_large_image">
    <!-- Keywords for your paper to be indexed by-->
    <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>QSTNet</title>
    <!--  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">-->
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
          rel="stylesheet">

    <link rel="stylesheet" href="static/css/bulma.min.css">
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/bulma-slider.min.js"></script>
    <script src="static/js/index.js"></script>

    <style>
        * {
            user-select: text; /* 允许所有元素的文本被选中 */
            caret-color: transparent; /* 隐藏文本光标 */
        }

        /*.slider-page {*/
        /*    user-select: none;*/
        /*    pointer-events: auto;*/
        /*}*/
    </style>
</head>
<body>

<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-2 publication-title">Quality-aware Spatio-temporal Transformer Network for RGBT Tracking</h1>
                    <div class="is-size-5 publication-authors">
                        <!-- Paper authors -->
                        <span class="author-block">
                <span>Zhaodong Ding</span>,</span>
                        <span class="author-block">
                  <span>Chenglong Li</span><sup>†</sup>,</span>
                        <span class="author-block">
                    <span>Tao Wang</span></sup>,</span>
                        </span>
                        <span class="author-block">
                            <span>Futian Wang</span>
                        </span>
                    </div>

                    <div class="is-size-5 publication-authors">
                        <div>
                        <span class="author-block">Anhui University</span> </div>
                        <span class="eql-cntrb"><small><sup>†</sup>Corresponding Author</small></span>
                    </div>

                    <div class="column has-text-centered" style="user-select: none; pointer-events: auto;">
                        <div class="publication-links">
                            <!-- Arxiv PDF link -->
                            <span class="link-block">
                        <a href="javascript:void(0);"
                           class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                            <!-- Github link -->
                            <span class="link-block">
                    <a href="https://github.com/dongdong2061/QSTNet"
                       class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                            <!-- ArXiv abstract Link -->
                            <!--                <span class="link-block">-->
                            <!--                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"-->
                            <!--                  class="external-link button is-normal is-rounded is-dark">-->
                            <!--                  <span class="icon">-->
                            <!--                    <i class="ai ai-arxiv"></i>-->
                            <!--                  </span>-->
                            <!--                  <span>arXiv</span>-->
                            <!--                </a>-->
                            <!--              </span>-->
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
    <div class="container is-max-desktop">
        <div class="hero-body">
            <video poster="" id="tree" autoplay controls muted loop height="100%">
                <!-- Your video here -->
                <source src="static/videos/video.mp4"
                        type="video/mp4">
            </video>
<!--            <h2 class="subtitle has-text-centered"></h2>-->
        </div>
    </div>
</section>
<!-- End teaser video-->

<!-- Paper abstract -->
<section class="section hero is-light">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Abstract</h2>
                <div class="content has-text-justified">
                    <p>
          Transformer-based RGBT tracking has attracted much attention due to the strong modeling capacity of self attention and cross attention mechanisms.These attention mechanisms utilize the correlations among tokens to construct powerful feature representations, but are easily affected by low-quality tokens.To address this issue, we propose a novel Quality-aware Spatio-temporal Transformer Network (QSTNet), which calculates the quality weights of tokens in search regions based on the correlation with multimodal template tokens to suppress the negative effects of low-quality tokens in spatio-temporal feature representations, for robust RGBT tracking. In particular, we argue that the correlation between search tokens of one modality and multimodal template tokens could reflect the quality of these search tokens, and thus design the Quality-aware Token Weighting Module (QTWM) based on the correlation matrix of search and template tokens to suppress the negative effects of low-quality tokens.Specifically, we calculate the difference matrix derived from the attention matrices of the search tokens from both modalities and the multimodal template tokens, and then assign the quality weight for each search token based on the difference matrix, which reflects the relative correlation of search tokens from different modalities to multimodal template tokens.In addition, we propose the Prompt-based Spatio-temporal Encoder Module (PSEM) to utilize spatio-temporal multimodal information while alleviating the impact of low-quality spatio-temporal features.Extensive experiments on four RGBT benchmark datasets demonstrate that the proposed QSTNet exhibits superior performance compared to other state-of-the-art tracking methods.
                    </p>
                </div>
            </div>
        </div>
    </div>
</section>
<!-- End paper abstract -->

<section class="section hero is-small">
    <div class="container is-max-desktop">
        <div class="columns is-centered">
            <div class="column is-full">
                <div class="content has-text-centered">
                    <h2 class="title is-3">Framework</h2>
                    <img src="static/images/pipeline.png" alt="Normal and Anomalous Representations"
                         class="center-image">
                    <div class="level-set has-text-justified">
                        <p>
                        The overall framework of our method. 
                        The dynamic modal fusion encoder is constructed by integrating the QTWM into the encoder layers. The Prompt-based Spatio-temporal Encoder Module (PSEM) is built by inserting the spatio-temporal prompt generator into the 12th encoder layer. 
                        During the tracking stage, the PSEM mines multimodal spatio-temporal cues to enhance target features, and the output multimodal spatio-temporal tokens are propagated to subsequent frames to exploit spatio-temporal cues.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="section hero is-small">
    <div class="container is-max-desktop">
        <div class="columns is-centered">
            <div class="column is-full">
                <div class="content has-text-centered">
                    <h2 class="title is-3">Main Reults</h2>
                    <img src="static/images/results.png" alt="Normal and Anomalous Representations"
                         class="center-image">
                </div>
            </div>
        </div>
    </div>
</section>

<section class="section hero is-small">
    <div class="container is-max-desktop">
        <div class="columns is-centered">
            <div class="column is-full">
                <div class="content has-text-centered">
                    <h2 class="title is-3"> Attribute-based Performance</h2>
                    <img width="70%" src="static/images/attr.png" alt="Normal and Anomalous Representations"
                         class="center-image">
                    <div class="level-set has-text-justified">
                        <p>
                        In all attribute conditions, our method achieves state-of-the-art performance in 16 attributes.Specifically, our method significantly outperforms existing state-of-the-art algorithms on the attribute subsets of PO, HO, BC, SA and FM, with improvements of 3.5%/3.7%/2.5%, 4.3%/3.6%/2.4%, 4.4%/1.1%/3.4%, 5.5%/5.4%/4.4%, and 3.2%/3.7%/3.5% in the PR/NPR/SR metrics, respectively.We attribute the performance improvements in these challenging scenarios to the effective quality-aware multimodal fusion and the successful exploitation of spatio-temporal information.However, our method does not perform as well as other RGBT trackers with the OV attribute scenario.
                        OV indicates that the tracked target leaves the camera's field of view, meaning the target disappears and is no longer present within the ground truth bounding box.
                        Since the proposed QTWM measures token quality based on the correlation between the template and the search region, it may attend to the most similar object when the target is absent from the search area. Nevertheless, by leveraging spatio-temporal information, the tracker can quickly recover and resume tracking the correct target once it reappears.
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>



<section class="section hero is-small">
    <div class="container is-max-desktop">
        <div class="columns is-centered">
            <div class="column is-full">
                <div class="content has-text-centered">
                    <h2 class="title is-3">Visualization</h2>
                    <img src="static/images/vis.jpg" alt="Normal and Anomalous Representations"
                         class="center-image">
                </div>
            </div>
        </div>
    </div>
</section>


<!-- Video carousel -->
<!--<section class="hero is-small">-->
<!--  <div class="hero-body">-->
<!--    <div class="container">-->
<!--      <h2 class="title is-3">Another Carousel</h2>-->
<!--      <div id="results-carousel" class="carousel results-carousel">-->
<!--        <div class="item item-video1">-->
<!--          <video poster="" id="video1" autoplay controls muted loop height="100%">-->
<!--            &lt;!&ndash; Your video file here &ndash;&gt;-->
<!--            <source src="static/videos/carousel1.mp4"-->
<!--            type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-video2">-->
<!--          <video poster="" id="video2" autoplay controls muted loop height="100%">-->
<!--            &lt;!&ndash; Your video file here &ndash;&gt;-->
<!--            <source src="static/videos/carousel2.mp4"-->
<!--            type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-video3">-->
<!--          <video poster="" id="video3" autoplay controls muted loop height="100%">\-->
<!--            &lt;!&ndash; Your video file here &ndash;&gt;-->
<!--            <source src="static/videos/carousel3.mp4"-->
<!--            type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--      </div>-->
<!--    </div>-->
<!--  </div>-->
<!--</section>-->
<!-- End video carousel -->


<!-- Paper poster -->
<!--<section class="hero is-small is-light">-->
<!--  <div class="hero-body">-->
<!--    <div class="container">-->
<!--      <h2 class="title">Poster</h2>-->

<!--      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">-->
<!--          </iframe>-->
<!--        -->
<!--      </div>-->
<!--    </div>-->
<!--  </section>-->
<!--End paper poster -->


<!--BibTex citation -->
<!-- <section class="section is-light" id="BibTeX">
    <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre><code>
    @inproceedings{shao2025pura,
        title={PURA: Parameter Update-Recovery Test-Time Adaption for RGB-T Tracking},
        author={Shao, Zekai and Hu, Yufan and Fan, Bin and Liu, Hongmin},
        booktitle={Proceedings of the Computer Vision and Pattern Recognition Conference},
        pages={22089--22098},
        year={2025}
    }
      </code></pre>
    </div>
</section> -->
<!--End BibTex citation -->


<section class="section hero is-light">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <div class="content">
                    <p>
                        This page was built using the <a style="color: #209cee;"
                                                         href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                                                         target="_blank">Academic
                        Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io"
                                                                                target="_blank">Nerfies</a> project
                        page.
                        <br>This website is licensed under a <a style="color: #209cee;" rel="license"
                                                                href="http://creativecommons.org/licenses/by-sa/4.0/"
                                                                target="_blank">Creative
                        Commons Attribution-ShareAlike 4.0 International License</a>.
                    </p>
                </div>
            </div>
        </div>
    </div>
</section>


<!--<footer class="footer">-->
<!--    <div class="container">-->
<!--        <div class="columns is-centered has-text-centered">-->
<!--            <div class="column is-8">-->
<!--                <div class="content has-text-justified">-->
<!--                    <p>-->
<!--                        This page was built using the <a-->
<!--                            href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic-->
<!--                        Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io"-->
<!--                                                                                target="_blank">Nerfies</a> project-->
<!--                        page.-->
<!--                        <br>This website is licensed under a <a rel="license"-->
<!--                                                                href="http://creativecommons.org/licenses/by-sa/4.0/"-->
<!--                                                                target="_blank">Creative-->
<!--                        Commons Attribution-ShareAlike 4.0 International License</a>.-->
<!--                    </p>-->

<!--                </div>-->
<!--            </div>-->
<!--        </div>-->
<!--    </div>-->
<!--</footer>-->

</body>
</html>


